{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4603a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install --upgrade seaborn matplotlib\n",
    "#%pip install 'pandas<2.2.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d566bb99-6808-4976-8476-ed05b7941b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('../../top_rated_scotch.csv')\n",
    "df = df[df['variety'].notna()] # remove any NaN values as it blows up serialization\n",
    "data = df.sample(10).to_dict('records') # Get only 700 records. More records will make it slower to index\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af8bce2c-e123-498a-a5f2-cefffd17fc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import models, QdrantClient\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280f15c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b0e4be5-7518-4458-bf47-6913ef9a72a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1d1b433e35b4992b1c45553f3116864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80a948955eee492b913de130576aa97f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c5209cd9dfc4dd79dcdfb42c4e0489f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac7ce40f541430899f2067664eb6b1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea47ec71bb4d4d51acdb2ede04be2be0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bca6316fc774b39853b0f3b6aaa5898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "607cd83736864b128fabdd9b317c123e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc2fd15a484848f29e4c4b94b74ae186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "329450c4da724748982a81f09720355f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cb6b08776f64eff8948fc9403b21e7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70017f0c81224bb18b52634a4101f408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder = SentenceTransformer('all-MiniLM-L6-v2') # Model to create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efa031d-b18a-4db1-9c34-9989a15c822b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the vector database client\n",
    "qdrant = QdrantClient(\":memory:\") # Create in-memory Qdrant instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c03be93-a076-425e-8df1-5a8b6367e558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create collection to store wines\n",
    "qdrant.recreate_collection(\n",
    "    collection_name=\"top_wines\",\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=encoder.get_sentence_embedding_dimension(), # Vector size is defined by used model\n",
    "        distance=models.Distance.COSINE\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655d08af-758f-4338-b112-cf94045c7b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize!\n",
    "qdrant.upload_points(\n",
    "    collection_name=\"top_wines\",\n",
    "    points=[\n",
    "        models.PointStruct(\n",
    "            id=idx,\n",
    "            vector=encoder.encode(doc[\"notes\"]).tolist(),\n",
    "            payload=doc,\n",
    "        ) for idx, doc in enumerate(data) # data is the variable holding all the wines\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23bc999",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"Suggest me an amazing Malbec wine from Argentina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c9bff5-db38-4a98-b542-cd173af11b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search time for awesome wines!\n",
    "\n",
    "hits = qdrant.search(\n",
    "    collection_name=\"top_wines\",\n",
    "    query_vector=encoder.encode(user_prompt).tolist(),\n",
    "    limit=3\n",
    ")\n",
    "for hit in hits:\n",
    "  print(hit.payload, \"score:\", hit.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33243e5d-9e0d-4ec4-98e9-3fc56b8bdb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a variable to hold the search results\n",
    "search_results = [hit.payload for hit in hits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c2b91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now time to connect to the local large language model\n",
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    base_url=\"http://127.0.0.1:8080/v1\", # \"http://<Your api-server IP>:port\"\n",
    "    api_key = \"sk-no-key-required\"\n",
    ")\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"LLaMA_CPP\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are chatbot, a wine specialist. Your top priority is to help guide users into selecting amazing wine and guide them with their requests.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Suggest me an amazing Malbec wine from Argentina\"},\n",
    "        {\"role\": \"assistant\", \"content\": str(search_results)}\n",
    "    ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
